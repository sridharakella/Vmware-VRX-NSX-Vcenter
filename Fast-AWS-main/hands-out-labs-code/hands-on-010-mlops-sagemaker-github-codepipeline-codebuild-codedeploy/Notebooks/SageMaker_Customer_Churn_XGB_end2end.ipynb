{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Model Building and Deployment "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook we show how to use Amazon SageMaker to develop, train, tune and deploy a XGBoost model. Sythetic customer churn data is used. \n",
    "\n",
    "The data is in AWS public S3 bucket: s3://sagemaker-sample-files/datasets/tabular/synthetic/churn.txt\n",
    "\n",
    "Sklearn Processor is used to process the raw data.\n",
    "\n",
    "* XGBoost https://sagemaker.readthedocs.io/en/stable/frameworks/xgboost/using_xgboost.html?highlight=xgboost\n",
    "* Doc https://sagemaker.readthedocs.io/en/stable/using_sklearn.html\n",
    "* SDK https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html\n",
    "* boto3 https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#client\n",
    " \n",
    "**This sample is provided for demonstration purposes, make sure to conduct appropriate testing if derivating this code for your own use-cases!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name Sagemaker-custom-role already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"AttachedPolicies\": [\n",
      "        {\n",
      "            \"PolicyName\": \"AmazonSageMakerFullAccess\",\n",
      "            \"PolicyArn\": \"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# create Sagemaker Full Access Assume Role, https://repost.aws/knowledge-center/iam-assume-role-cli\n",
    "!aws iam create-role --role-name Sagemaker-custom-role --assume-role-policy-document file://assume-role.json\n",
    "!aws iam attach-role-policy --role-name Sagemaker-custom-role --policy-arn \"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\"\n",
    "!aws iam list-attached-role-policies --role-name Sagemaker-custom-role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()  # this could also be a hard-coded bucket name\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(region)\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='Sagemaker-custom-role')['Role']['Arn']\n",
    "print(role)\n",
    "\n",
    "project_name = \"test_pro\"\n",
    "project_id = \"test_id\"\n",
    "print(f\"sagemaker role arn <{role}>\")\n",
    "\n",
    "assert(len(project_name) <= 15 ) # the project name should not have more than 15 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bucket)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data to S3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load raw data from the public S3 bucket to your own S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-sample-files/datasets/tabular/synthetic/churn.txt s3://{bucket}/sagemaker/DEMO-xgboost-churn/data/RawData.csv "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare script to process raw data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create preprocessing script. This script will be used by SageMaker process job instance to preocess raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "\"\"\"Preprocess the customer churn dataset.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import pathlib\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting preprocessing.\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-data\", type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "    pathlib.Path(f\"{base_dir}/data\").mkdir(parents=True, exist_ok=True)\n",
    "    input_data = args.input_data\n",
    "    print(input_data)\n",
    "    bucket = input_data.split(\"/\")[2]\n",
    "    key = \"/\".join(input_data.split(\"/\")[3:])\n",
    "\n",
    "    logger.info(\"Downloading data from bucket: %s, key: %s\", bucket, key)\n",
    "    fn = f\"{base_dir}/data/raw-data.csv\"\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    s3.Bucket(bucket).download_file(key, fn)\n",
    "\n",
    "    logger.info(\"Reading downloaded data.\")\n",
    "\n",
    "    # read in csv\n",
    "    df = pd.read_csv(fn)\n",
    "\n",
    "    # drop the \"Phone\" feature column\n",
    "    df = df.drop([\"Phone\"], axis=1)\n",
    "\n",
    "    # Change the data type of \"Area Code\"\n",
    "    df[\"Area Code\"] = df[\"Area Code\"].astype(object)\n",
    "\n",
    "    # Drop several other columns\n",
    "    df = df.drop([\"Day Charge\", \"Eve Charge\", \"Night Charge\", \"Intl Charge\"], axis=1)\n",
    "\n",
    "    # Convert categorical variables into dummy/indicator variables.\n",
    "    model_data = pd.get_dummies(df)\n",
    "\n",
    "    # Create one binary classification target column\n",
    "    model_data = pd.concat(\n",
    "        [\n",
    "            model_data[\"Churn?_True.\"],\n",
    "            model_data.drop([\"Churn?_False.\", \"Churn?_True.\"], axis=1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Split the data\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        model_data.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(model_data)), int(0.9 * len(model_data))],\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(train_data).to_csv(\n",
    "        f\"{base_dir}/train/train.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(validation_data).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test_data).to_csv(\n",
    "        f\"{base_dir}/test/test.csv\", header=False, index=False\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "        name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "        name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "        name=\"ModelApprovalStatus\",\n",
    "        default_value=\"Approved\",  # ModelApprovalStatus can be set to a default of \"Approved\" if you don't want manual approval.\n",
    "    )\n",
    "\n",
    "input_data = ParameterString(\n",
    "        name=\"InputDataUrl\",\n",
    "        default_value=f\"s3://{sagemaker_session.default_bucket()}/sagemaker/DEMO-xgboost-churn/data/RawData.csv\",  # Change this to point to the s3 location of your raw input data.\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker Process instance with sklearn image is used to process raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type= \"ml.m5.xlarge\", #\"local\", \n",
    "    instance_count= 1, \n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processed data is saved back to S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "input_data=f\"s3://{sagemaker_session.default_bucket()}/sagemaker/DEMO-xgboost-churn/data/RawData.csv\"\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code=\"preprocess.py\", \n",
    "    inputs=[\n",
    "         ProcessingInput(source=f\"s3://{sagemaker_session.default_bucket()}/sagemaker/DEMO-xgboost-churn/data/RawData.csv\", destination=\"/opt/ml/processing/input\"),\n",
    "    ], \n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    arguments=[\"--input-data\", input_data],\n",
    ")\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training and validation data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train=preprocessing_job_description['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_validation=preprocessing_job_description['ProcessingOutputConfig']['Outputs'][1]['S3Output']['S3Uri']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "content_type = \"csv\"\n",
    "train_input = TrainingInput(s3_input_train, content_type=content_type)\n",
    "validation_input = TrainingInput(s3_input_validation, content_type=content_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sagemaker/xgboost_cutomer_churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.2-1\n"
     ]
    }
   ],
   "source": [
    "container=sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    hyperparameters=hyperparameters,\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the XGboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-06-20-11-47-20-805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-20 11:47:21 Starting - Starting the training job...\n",
      "2023-06-20 11:47:46 Starting - Preparing the instances for training......\n",
      "2023-06-20 11:48:53 Downloading - Downloading input data...\n",
      "2023-06-20 11:49:23 Training - Downloading the training image......\n",
      "2023-06-20 11:50:13 Training - Training image download completed. Training in progress..[2023-06-20 11:50:30.215 ip-10-2-118-242.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "INFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\n",
      "INFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\n",
      "Returning the value itself\n",
      "INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "INFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\n",
      "INFO:root:Determined delimiter of CSV input is ','\n",
      "INFO:root:Determined delimiter of CSV input is ','\n",
      "INFO:root:Determined delimiter of CSV input is ','\n",
      "INFO:root:Determined delimiter of CSV input is ','\n",
      "INFO:root:Single node training.\n",
      "[2023-06-20 11:50:30.332 ip-10-2-118-242.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2023-06-20 11:50:30.333 ip-10-2-118-242.ec2.internal:7 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2023-06-20 11:50:30.333 ip-10-2-118-242.ec2.internal:7 INFO profiler_config_parser.py:102] User has disabled profiler.\n",
      "[2023-06-20 11:50:30.334 ip-10-2-118-242.ec2.internal:7 INFO hook.py:253] Saving to /opt/ml/output/tensors\n",
      "[2023-06-20 11:50:30.334 ip-10-2-118-242.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "INFO:root:Debug hook created from config\n",
      "INFO:root:Train matrix has 3500 rows and 99 columns\n",
      "INFO:root:Validation matrix has 1000 rows\n",
      "[0]#011train-error:0.12486#011validation-error:0.13200\n",
      "[2023-06-20 11:50:30.348 ip-10-2-118-242.ec2.internal:7 INFO hook.py:413] Monitoring the collections: metrics\n",
      "[2023-06-20 11:50:30.351 ip-10-2-118-242.ec2.internal:7 INFO hook.py:476] Hook is writing from the hook with pid: 7\n",
      "[1]#011train-error:0.10200#011validation-error:0.10700\n",
      "[2]#011train-error:0.08971#011validation-error:0.09900\n",
      "[3]#011train-error:0.09257#011validation-error:0.09900\n",
      "[4]#011train-error:0.09257#011validation-error:0.09600\n",
      "[5]#011train-error:0.08971#011validation-error:0.09100\n",
      "[6]#011train-error:0.08514#011validation-error:0.08700\n",
      "[7]#011train-error:0.08171#011validation-error:0.08300\n",
      "[8]#011train-error:0.07686#011validation-error:0.08000\n",
      "[9]#011train-error:0.07486#011validation-error:0.08100\n",
      "[10]#011train-error:0.07257#011validation-error:0.07800\n",
      "[11]#011train-error:0.06943#011validation-error:0.07600\n",
      "[12]#011train-error:0.06914#011validation-error:0.07700\n",
      "[13]#011train-error:0.06971#011validation-error:0.07900\n",
      "[14]#011train-error:0.06629#011validation-error:0.08000\n",
      "[15]#011train-error:0.06514#011validation-error:0.07700\n",
      "[16]#011train-error:0.06571#011validation-error:0.07700\n",
      "[17]#011train-error:0.06429#011validation-error:0.07500\n",
      "[18]#011train-error:0.06371#011validation-error:0.07500\n",
      "[19]#011train-error:0.06429#011validation-error:0.07300\n",
      "[20]#011train-error:0.06400#011validation-error:0.07300\n",
      "[21]#011train-error:0.06400#011validation-error:0.07200\n",
      "[22]#011train-error:0.06400#011validation-error:0.07200\n",
      "[23]#011train-error:0.06371#011validation-error:0.07300\n",
      "[24]#011train-error:0.06257#011validation-error:0.07300\n",
      "[25]#011train-error:0.06086#011validation-error:0.07100\n",
      "[26]#011train-error:0.06086#011validation-error:0.07000\n",
      "[27]#011train-error:0.05914#011validation-error:0.06900\n",
      "[28]#011train-error:0.05771#011validation-error:0.06900\n",
      "[29]#011train-error:0.05771#011validation-error:0.06900\n",
      "[30]#011train-error:0.05743#011validation-error:0.06500\n",
      "[31]#011train-error:0.05543#011validation-error:0.06700\n",
      "[32]#011train-error:0.05600#011validation-error:0.06800\n",
      "[33]#011train-error:0.05400#011validation-error:0.07000\n",
      "[34]#011train-error:0.05343#011validation-error:0.06700\n",
      "[35]#011train-error:0.05314#011validation-error:0.07100\n",
      "[36]#011train-error:0.05286#011validation-error:0.07100\n",
      "[37]#011train-error:0.05286#011validation-error:0.07200\n",
      "[38]#011train-error:0.05257#011validation-error:0.07000\n",
      "[39]#011train-error:0.05343#011validation-error:0.06800\n",
      "[40]#011train-error:0.05257#011validation-error:0.06800\n",
      "[41]#011train-error:0.05286#011validation-error:0.06900\n",
      "[42]#011train-error:0.05143#011validation-error:0.06800\n",
      "[43]#011train-error:0.05029#011validation-error:0.06700\n",
      "[44]#011train-error:0.05029#011validation-error:0.06700\n",
      "[45]#011train-error:0.04914#011validation-error:0.06700\n",
      "[46]#011train-error:0.04914#011validation-error:0.06700\n",
      "[47]#011train-error:0.04943#011validation-error:0.06800\n",
      "[48]#011train-error:0.04971#011validation-error:0.06800\n",
      "[49]#011train-error:0.04886#011validation-error:0.06800\n",
      "\n",
      "2023-06-20 11:50:50 Uploading - Uploading generated training model\n",
      "2023-06-20 11:50:50 Completed - Training job completed\n",
      "Training seconds: 117\n",
      "Billable seconds: 117\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': train_input, 'validation': validation_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3 = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=xgb.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact persisted at \" + artifact)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an endpoint using SageMaker SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2023-06-20-12-03-03-421\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2023-06-20-12-03-03-421\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2023-06-20-12-03-03-421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(\n",
    "initial_instance_count = 1,\n",
    "instance_type = 'ml.m4.xlarge',\n",
    "serializer = CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: sagemaker-xgboost-2023-06-20-12-03-03-421\n"
     ]
    }
   ],
   "source": [
    "print(f'Endpoint name: {xgb_predictor.endpoint_name}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21.        ,   0.        ,   0.84385859,   3.        ,\n",
       "         1.34772502,   0.        ,   4.74977594, 350.        ,\n",
       "         4.38414605,   8.        ,   7.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   1.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   1.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   1.        ,\n",
       "         0.        ,   1.        ,   0.        ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test.csv',header=None)\n",
    "test_data.to_numpy()[2,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.to_numpy()[:1,1:])  #test_data.to_numpy()[2,1:]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of invoking ML Endpoint model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "test_data=pd.read_csv('test.csv',header=None)\n",
    "testdata1=test_data.iloc[0:1,1:]\n",
    "\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "Endpoint_name='' #<your endpoint name> # update to your own endpoint name\n",
    "\n",
    "prediction = runtime.invoke_endpoint(\n",
    "    EndpointName=Endpoint_name,\n",
    "    Body=testdata1.to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    ContentType=\"text/csv\",\n",
    "    Accept= \"text/csv\",\n",
    ")\n",
    "\n",
    "print(prediction[\"Body\"].read())"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
