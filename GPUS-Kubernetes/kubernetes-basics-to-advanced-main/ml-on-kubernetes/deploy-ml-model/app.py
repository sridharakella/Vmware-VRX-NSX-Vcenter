"""
Iris Classification Model Serving API

A FastAPI application that serves predictions from a pre-trained
Random Forest classifier for Iris flower classification.

This API is designed to be deployed in Kubernetes and demonstrates
a simple ML model serving pattern. The model is loaded from a
pickle file (model.pkl) generated by train_model.py.

Endpoints:
    GET  /healthz  - Health check endpoint for Kubernetes probes
    POST /predict  - Make predictions on Iris flower measurements

Expected input format for /predict:
    {"data": [sepal_length, sepal_width, petal_length, petal_width]}

Example:
    curl -X POST http://localhost:8000/predict \\
         -H "Content-Type: application/json" \\
         -d '{"data": [5.1, 3.5, 1.4, 0.2]}'

    Response: {"prediction": [0]}  # 0=Setosa, 1=Versicolor, 2=Virginica
"""

from fastapi import FastAPI
from pydantic import BaseModel
import joblib, numpy as np

# Initialize FastAPI application
app = FastAPI()

# Load the pre-trained model from disk at startup
# The model.pkl file is created by running train_model.py
model = joblib.load("model.pkl")


class Instance(BaseModel):
    """
    Request schema for prediction endpoint.

    Attributes:
        data: List of 4 float values representing Iris measurements:
              [sepal_length, sepal_width, petal_length, petal_width]
    """
    data: list


@app.get("/healthz")
def healthz():
    """
    Health check endpoint for Kubernetes liveness/readiness probes.

    Returns:
        dict: {"status": "ok"} if the service is healthy
    """
    return {"status": "ok"}


@app.post("/predict")
def predict(inst: Instance):
    """
    Make a prediction for Iris flower classification.

    Takes a list of 4 measurements and returns the predicted class.
    Classes: 0 = Setosa, 1 = Versicolor, 2 = Virginica

    Args:
        inst: Instance object containing the 'data' list of measurements

    Returns:
        dict: {"prediction": [class_id]} where class_id is 0, 1, or 2
    """
    # Convert input list to numpy array and reshape for sklearn
    # reshape(1, -1) converts [a, b, c, d] to [[a, b, c, d]] (single sample)
    # sklearn models expect 2D arrays where each row is a sample
    arr = np.array(inst.data).reshape(1, -1)

    # Run prediction and convert numpy array to Python list for JSON serialization
    pred = model.predict(arr).tolist()

    return {"prediction": pred}
